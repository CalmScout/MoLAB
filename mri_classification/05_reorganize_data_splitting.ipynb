{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the names of the hospitals from the original `.mat` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "import typing\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import hashlib\n",
    "import shutil\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/storage_1/003_raw_gbm_met_classifier/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split names into two groups(new and old naming conventions), by the 3d symbol in the name: '_' or '-'\n",
    "# we process fnames from different hospitals in different ways\n",
    "new_conv = set()\n",
    "old_conv = set()\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for name in files:\n",
    "        if name[3] == '_':\n",
    "            new_conv.add(name)\n",
    "        elif name[3] == '-':\n",
    "            old_conv.add(name)\n",
    "#         print(os.path.join(root, name))\n",
    "#         print(name)\n",
    "\n",
    "# output our groups\n",
    "def print_group(group):\n",
    "    for el in group:\n",
    "        print(el)\n",
    "\n",
    "# print(\"New convention:\")\n",
    "# print_group(new_conv)\n",
    "\n",
    "# print(\"Old convention:\")\n",
    "# print_group(old_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitals = set()\n",
    "\n",
    "# processing `group_1`\n",
    "for fname in new_conv:\n",
    "    tmp = fname.split(\"_\")[2]\n",
    "    hospital = re.search(r\"[a-zA-Z]*\", tmp).group()\n",
    "    hospitals.add(hospital)\n",
    "    \n",
    "# processing `group_2`\n",
    "for fname in old_conv:\n",
    "    hospital = fname.split(\"-\")[1][:2]\n",
    "    hospitals.add(hospital)\n",
    "\n",
    "print(hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hospital_from_filename(fpath:Path) -> str:\n",
    "    \"\"\"\n",
    "    Extracts hospital label from filename. Assume filename in one from two file formats.\n",
    "    Ignores files with extension different from `.mat`.\n",
    "    \"\"\"\n",
    "    fpath = Path(fpath)\n",
    "    # we process only `.mat` files\n",
    "    if fpath.suffix != \".mat\":\n",
    "        return None\n",
    "    fname = fpath.stem\n",
    "    # detect one of two possible name conventions\n",
    "    if fname[3] == '_':\n",
    "        tmp = fname.split(\"_\")[2]\n",
    "        label = re.search(r\"[a-zA-Z]*\", tmp).group()\n",
    "        return label.upper()\n",
    "    elif fname[3] == '-':\n",
    "        label = fname.split(\"-\")[1][:2]\n",
    "        return label.upper()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported filename format: {}\".format(fpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(path):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name), '->', get_hospital_from_filename(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace labels 'CREAL' to 'CR' in the names of the `.mat` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_label = r\"CREAL\"\n",
    "new_label = \"CR\"\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for name in files:\n",
    "        full_path = os.path.join(root, name)\n",
    "        if get_hospital_from_filename(full_path) == old_label:\n",
    "            new_name = tmp[0] + \"_\" + tmp[1] + \"_\" + re.sub(old_label, new_label, tmp[2]) + \"_\" +  tmp[3]\n",
    "            os.rename(full_path, os.path.join(root, new_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if we have duplicates\n",
    "Iterate over all files and count occurence of each of the filename in the folder. Print duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_count = dict()\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        if fname in d_count:\n",
    "            d_count[fname] += 1\n",
    "        else:\n",
    "            d_count[fname] = 1\n",
    "\n",
    "# print occurences more than 1 time and add to set of duplicate names\n",
    "duplicates = set()\n",
    "for key in d_count:\n",
    "    if d_count[key] > 1:\n",
    "        print(key, \":\", d_count[key])\n",
    "        duplicates.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dict()\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        if fname in names:\n",
    "            names[fname].append(os.path.join(root, fname))\n",
    "        else:\n",
    "            tmp = [os.path.join(root, fname)]\n",
    "            names[fname] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in duplicates:\n",
    "    print(fname)\n",
    "    for el in names[fname]:\n",
    "        print(el)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the files are the same, or we have different files with the same names(md5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_as_bytes(file):\n",
    "    with file:\n",
    "        return file.read()\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        if fname in duplicates:\n",
    "            full_path = os.path.join(root, fname)\n",
    "            print(full_path)\n",
    "            print(fname, hashlib.md5(file_as_bytes(open(full_path, 'rb'))).hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, files are different - different masks. We will keep all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_counter = 0\n",
    "for root, dirs, files in os.walk(path / \"gbm\"):\n",
    "    gbm_counter += len(files)\n",
    "print(\"Number of 'gbm' '.mat' files: {}.\".format(gbm_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_counter = 0\n",
    "for root, dirs, files in os.walk(path / \"met\"):\n",
    "    met_counter += len(files)\n",
    "\n",
    "met_counter -= (len(duplicates) + 1)\n",
    "print(\"Number of 'met' '.mat' files: {}.\".format(met_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}\".format(met_counter / gbm_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we decided to keep all copies of the data. Then we have to rename duplicated filenames not to overwrite `.png` images during process of generation. So, iterate over all files, create dictionary of filename counters and in the case if we have already such filename in the dictionary - modify name of the current file by adding `\"_copy_<value in  dictionary>\"` before the file extension. Increase current value of the dictionary by 1. After such modification it is necessary to recalculate `.png` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_count = dict()\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        if fname in d_count:\n",
    "            name, ext = os.path.splitext(fname)\n",
    "            new_fname = name + \"_copy_{}\".format(d_count[fname]) + ext\n",
    "            shutil.move(os.path.join(root, fname), os.path.join(root, new_fname))\n",
    "            d_count[fname] += 1\n",
    "        else:\n",
    "            d_count[fname] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_count = dict()\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for fname in files:\n",
    "        if fname in d_count:\n",
    "            d_count[fname] += 1\n",
    "        else:\n",
    "            d_count[fname] = 1\n",
    "\n",
    "# print occurences more than 1 time and add to set of duplicate names\n",
    "duplicates = set()\n",
    "for key in d_count:\n",
    "    if d_count[key] > 1:\n",
    "        print(key, \":\", d_count[key])\n",
    "        duplicates.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize `train` / `valid` splitting of the data with respect to the hospital\n",
    "First we need to create Pandas DataFrame which would contain information about hospital and class of the tumor at each of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_labels_from_imagenet_like_folder(root:Path) -> List:\n",
    "    \"\"\"\n",
    "    Returns names of folders in the folder.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for el in os.listdir(root):\n",
    "        # if doesn't have extension - folder\n",
    "        if len(el.split('.')) == 1:\n",
    "            result.append(el)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_labels_from_imagenet_like_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_df_from_folder(path:Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Creates dataframe with information about each `.mat` file in the `path` tree.\n",
    "    \"\"\"\n",
    "    d_hospitals = dict()\n",
    "    labels = _get_labels_from_imagenet_like_folder(path)\n",
    "    for label in labels:\n",
    "        for root, dirs, files in os.walk(path / label):\n",
    "            # create necessary dictionaries\n",
    "            for fname in files:\n",
    "                if Path(fname).suffix == \".mat\":\n",
    "                    key = os.path.splitext(fname)[0]\n",
    "                    d_hospitals[key] = (get_hospital_from_filename(fname), label, os.path.join(root, fname))\n",
    "    df = pd.DataFrame.from_dict(d_hospitals, orient='index', columns=['hospital', 'label', 'path'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _create_df_from_folder(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path / \"split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(path / \"split.csv\", index_col=0)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split dataset into `train` (80 %) and `valid` (20 %) but in such way that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('hospital').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['hospital', 'label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hospital.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_df_to_train_valid(df:DataFrame, pct:float = 0.8) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Generates DataFrame with new `data_split` column with values from {\"train\", \"valid\"}.\n",
    "    From each hospital for each category randomly assign `pct` labels of \"train\", the rest are \"valid\".\n",
    "    \"\"\"\n",
    "    result = df.copy(deep=True)\n",
    "    result[\"data_split\"] = [None] * result.shape[0]\n",
    "    for hospital in result.hospital.unique():\n",
    "        # split by hospital\n",
    "        tmp = result[result[\"hospital\"] == hospital]\n",
    "        for label in tmp.label.unique():\n",
    "            # split by label in the hospital\n",
    "            tmp_per_label = tmp[tmp['label'] == label]\n",
    "            # index till which to split to `train`\n",
    "            index = np.random.permutation(tmp_per_label.index)\n",
    "            for idx_el in index[:int(pct * len(index))]:\n",
    "                # modify the whole dataframe\n",
    "                result.loc[[idx_el], ['data_split']] = 'train'\n",
    "            for idx_el in index[int(pct * len(index)):]:\n",
    "                result.loc[[idx_el], ['data_split']] = 'valid'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = _split_df_to_train_valid(df)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data splitting in dataframe\n",
    "pct = 0.8\n",
    "result = df.copy(deep=True)\n",
    "result[\"data_split\"] = [None] * result.shape[0]\n",
    "for hospital in result.hospital.unique():\n",
    "    # split by hospital\n",
    "    tmp = result[result[\"hospital\"] == hospital]\n",
    "    for label in tmp.label.unique():\n",
    "        # split by label in the hospital\n",
    "        tmp_per_label = tmp[tmp['label'] == label]\n",
    "        # index till which to split to `train`\n",
    "        index = np.random.permutation(tmp_per_label.index)\n",
    "        for idx_el in index[:int(pct * len(index))]:\n",
    "            # modify the whole dataframe\n",
    "            result.loc[[idx_el], ['data_split']] = 'train'\n",
    "        for idx_el in index[int(pct * len(index)):]:\n",
    "            result.loc[[idx_el], ['data_split']] = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"path\", \"data_split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lst = list(range(10))\n",
    "shuffle(tmp_lst)\n",
    "pivot_idx = int(len(tmp_lst) *  0.8)\n",
    "tmp_lst_train = tmp_lst[:pivot_idx]\n",
    "tmp_lst_valid = tmp_lst[pivot_idx:]\n",
    "print(tmp_lst)\n",
    "print(tmp_lst_train)\n",
    "print(tmp_lst_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index.values\n",
    "a_1 = np.arange(10)\n",
    "a_2 = np.random.permutation(a_1)\n",
    "a_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"path\", \"data_split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path / \"final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
